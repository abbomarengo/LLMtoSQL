{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch\n",
    "from torch.nn import Softmax\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from llmtosql.model import WikiSQLModel\n",
    "from llmtosql.trainer import Trainer\n",
    "from llmtosql.dataloader import WikiSQLDataset\n",
    "from llmtosql.utils.utils import plot_history, plot_history_base, load_model, load_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "path = 'model_output'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = WikiSQLModel(base_model_type='bert-base-uncased', attention_type='cross')\n",
    "model = load_model(model, 'model_output/model.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_set = WikiSQLDataset(type='test', model=model)\n",
    "test_loader = DataLoader(test_set, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sel = []\n",
    "agg = []\n",
    "conds = []\n",
    "with tqdm(test_loader, unit='batch') as tepoch:\n",
    "    for data in tepoch:\n",
    "        inputs, _ = model.unpack(data, device)\n",
    "        outputs = model(inputs)\n",
    "        predictions = model.predict(outputs)\n",
    "        sel.extend(predictions[0].tolist())\n",
    "        agg.extend(predictions[1].tolist())\n",
    "        for idx, cond in enumerate(predictions[2]):\n",
    "            if len(cond.shape) == 1:\n",
    "                cond = cond.unsqueeze(1)\n",
    "            if idx == 0:\n",
    "                max_num_conditions = torch.max(cond).item()\n",
    "                print(max_num_conditions)\n",
    "                if max_num_conditions == 0:\n",
    "                    cond_1 = cond_2, cond_3 = [[None]], [[None]], [[None]]\n",
    "                    break\n",
    "            elif idx == 1:\n",
    "                cond_1 = cond.T.tolist()\n",
    "                cond_1 = cond_1[:max_num_conditions]\n",
    "            elif idx == 2:\n",
    "                cond = cond - 1\n",
    "                cond_2 = cond.T.tolist()\n",
    "                cond_2 = cond_2[:max_num_conditions]\n",
    "            elif idx == 3:\n",
    "                outer_list = []\n",
    "                for condition in torch.transpose(predictions[2][3].T, 1, 2).tolist():\n",
    "                    batch_list = []\n",
    "                    for batch in condition:\n",
    "                        word_list = model.tokenizer.convert_ids_to_tokens(batch, skip_special_tokens=True)\n",
    "                        batch_list.append(' '.join(word_list))\n",
    "                    outer_list.append(batch_list)\n",
    "                cond_3 = outer_list\n",
    "                cond_3 = cond_3[:max_num_conditions]\n",
    "        print(cond_1, cond_2, cond_3)\n",
    "        all_conds = []\n",
    "        for c1, c2, c3 in zip(cond_1, cond_2, cond_3):\n",
    "            inner_all_conds = []\n",
    "            for b1, b2, b3 in zip(c1, c2, c3):\n",
    "                if b2 == -1:\n",
    "                    b1, b2, b3 = None, None, None\n",
    "                inner_all_conds.append((b1, b2, b3))\n",
    "            all_conds.append(inner_all_conds)\n",
    "        conds.extend([list(x) for x in zip(*all_conds)])\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final = []\n",
    "for s, a, c in zip(sel, agg, conds):\n",
    "    solution = {\n",
    "        \"query\": {\n",
    "            \"sel\":s,\n",
    "            \"agg\":a\n",
    "        }\n",
    "    }\n",
    "    if all([all([x is None for x in cond]) for cond in c]):\n",
    "        c = None\n",
    "    if c is not None:\n",
    "        solution[\"query\"][\"conds\"] = [list(x) for x in c]\n",
    "    final.append(solution)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "final"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "test_file = 'model_output/test_results.jsonl'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open(test_file, 'w+') as f:\n",
    "    for line in final:\n",
    "        json.dump(line, f)\n",
    "        f.write('\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
