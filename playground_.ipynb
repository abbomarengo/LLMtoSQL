{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import torch\n",
    "from torch.nn import Softmax\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from llmtosql.model import WikiSQLModel\n",
    "from llmtosql.trainer import Trainer\n",
    "from llmtosql.dataloader import WikiSQLDataset\n",
    "from llmtosql.utils.utils import plot_history, plot_history_base, load_model, load_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "path = 'model_output'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-08 08:26:50 [info     ] Using cross attention mechanism\n",
      "2023-05-08 08:26:50 [info     ] 3 heads model -- ['SELECT', 'AGG', 'CONDS']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = WikiSQLModel(base_model_type='bert-base-uncased', attention_type='cross')\n",
    "model = load_model(model, 'model_output/model.pth')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-05-08 08:26:55 [info     ] Tokenizing dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1762/15878 [00:01<00:10, 1386.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'m': [6], 'van': [7], 'der': [8], 'goten': [9], 'bel': [11]}) ['m', 'van', 'der', 'goten', 'bel']\n",
      "m name\n",
      "m the\n",
      "m 3\n",
      "m where\n",
      "m weightlifter\n",
      "m is\n",
      "m m\n",
      "m van\n",
      "m der\n",
      "m goten\n",
      "m \n",
      "m bel\n",
      "m \n",
      "van name\n",
      "van the\n",
      "van 3\n",
      "van where\n",
      "van weightlifter\n",
      "van is\n",
      "van m\n",
      "van van\n",
      "van der\n",
      "van goten\n",
      "van \n",
      "van bel\n",
      "van \n",
      "der name\n",
      "der the\n",
      "der 3\n",
      "der where\n",
      "der weightlifter\n",
      "der is\n",
      "der m\n",
      "der van\n",
      "der der\n",
      "der goten\n",
      "der \n",
      "der bel\n",
      "der \n",
      "goten name\n",
      "goten the\n",
      "goten 3\n",
      "goten where\n",
      "goten weightlifter\n",
      "goten is\n",
      "goten m\n",
      "goten van\n",
      "goten der\n",
      "goten goten\n",
      "goten \n",
      "goten bel\n",
      "goten \n",
      "bel name\n",
      "bel the\n",
      "bel 3\n",
      "bel where\n",
      "bel weightlifter\n",
      "bel is\n",
      "bel m\n",
      "bel van\n",
      "bel der\n",
      "bel goten\n",
      "bel \n",
      "bel bel\n",
      "bel \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▋        | 2600/15878 [00:01<00:09, 1355.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'baccalaureate': [6], 'college': [12]}) ['baccalaureate', 'college']\n",
      "baccalaureate what\n",
      "baccalaureate was\n",
      "baccalaureate the\n",
      "baccalaureate enrollment\n",
      "baccalaureate 2005\n",
      "baccalaureate for\n",
      "baccalaureate baccalaureate\n",
      "baccalaureate colleges\n",
      "baccalaureate ,\n",
      "baccalaureate for\n",
      "baccalaureate granite\n",
      "baccalaureate state\n",
      "baccalaureate college\n",
      "college what\n",
      "college was\n",
      "college the\n",
      "college enrollment\n",
      "college 2005\n",
      "college for\n",
      "college baccalaureate\n",
      "college colleges\n",
      "college ,\n",
      "college for\n",
      "college granite\n",
      "college state\n",
      "college college\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 3257/15878 [00:02<00:10, 1167.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'madison': [1], 'square': [2], 'garden': [3], 'new': [5, 8, 5, 8], 'york': [6, 9, 6, 9], 'city': [7, 15]}) ['madison', 'square', 'garden', 'new', 'york', 'city', 'new', 'york']\n",
      "madison when\n",
      "madison madison\n",
      "madison square\n",
      "madison garden\n",
      "madison \n",
      "madison new\n",
      "madison york\n",
      "madison city\n",
      "madison new\n",
      "madison york\n",
      "madison \n",
      "madison is\n",
      "madison the\n",
      "madison tournament\n",
      "madison venue\n",
      "madison city\n",
      "madison what\n",
      "madison is\n",
      "madison the\n",
      "madison conference\n",
      "madison tournament\n",
      "square when\n",
      "square madison\n",
      "square square\n",
      "square garden\n",
      "square \n",
      "square new\n",
      "square york\n",
      "square city\n",
      "square new\n",
      "square york\n",
      "square \n",
      "square is\n",
      "square the\n",
      "square tournament\n",
      "square venue\n",
      "square city\n",
      "square what\n",
      "square is\n",
      "square the\n",
      "square conference\n",
      "square tournament\n",
      "garden when\n",
      "garden madison\n",
      "garden square\n",
      "garden garden\n",
      "garden \n",
      "garden new\n",
      "garden york\n",
      "garden city\n",
      "garden new\n",
      "garden york\n",
      "garden \n",
      "garden is\n",
      "garden the\n",
      "garden tournament\n",
      "garden venue\n",
      "garden city\n",
      "garden what\n",
      "garden is\n",
      "garden the\n",
      "garden conference\n",
      "garden tournament\n",
      "new when\n",
      "new madison\n",
      "new square\n",
      "new garden\n",
      "new \n",
      "new new\n",
      "new york\n",
      "new city\n",
      "new new\n",
      "new york\n",
      "new \n",
      "new is\n",
      "new the\n",
      "new tournament\n",
      "new venue\n",
      "new city\n",
      "new what\n",
      "new is\n",
      "new the\n",
      "new conference\n",
      "new tournament\n",
      "york when\n",
      "york madison\n",
      "york square\n",
      "york garden\n",
      "york \n",
      "york new\n",
      "york york\n",
      "york city\n",
      "york new\n",
      "york york\n",
      "york \n",
      "york is\n",
      "york the\n",
      "york tournament\n",
      "york venue\n",
      "york city\n",
      "york what\n",
      "york is\n",
      "york the\n",
      "york conference\n",
      "york tournament\n",
      "city when\n",
      "city madison\n",
      "city square\n",
      "city garden\n",
      "city \n",
      "city new\n",
      "city york\n",
      "city city\n",
      "city new\n",
      "city york\n",
      "city \n",
      "city is\n",
      "city the\n",
      "city tournament\n",
      "city venue\n",
      "city city\n",
      "city what\n",
      "city is\n",
      "city the\n",
      "city conference\n",
      "city tournament\n",
      "new when\n",
      "new madison\n",
      "new square\n",
      "new garden\n",
      "new \n",
      "new new\n",
      "new york\n",
      "new city\n",
      "new new\n",
      "new york\n",
      "new \n",
      "new is\n",
      "new the\n",
      "new tournament\n",
      "new venue\n",
      "new city\n",
      "new what\n",
      "new is\n",
      "new the\n",
      "new conference\n",
      "new tournament\n",
      "york when\n",
      "york madison\n",
      "york square\n",
      "york garden\n",
      "york \n",
      "york new\n",
      "york york\n",
      "york city\n",
      "york new\n",
      "york york\n",
      "york \n",
      "york is\n",
      "york the\n",
      "york tournament\n",
      "york venue\n",
      "york city\n",
      "york what\n",
      "york is\n",
      "york the\n",
      "york conference\n",
      "york tournament\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 4986/15878 [00:03<00:08, 1284.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'tony': [2], 'oullivan': []}) ['tony', 'oullivan']\n",
      "tony what\n",
      "tony is\n",
      "tony tony\n",
      "tony osullivan\n",
      "tony county\n",
      "oullivan what\n",
      "oullivan is\n",
      "oullivan tony\n",
      "oullivan osullivan\n",
      "oullivan county\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 6244/15878 [00:04<00:08, 1192.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'–': []}) ['–']\n",
      "– which\n",
      "– league\n",
      "– that\n",
      "– has\n",
      "– no\n",
      "– playoffs\n",
      "– in\n",
      "– the\n",
      "– year\n",
      "– of\n",
      "– 2008–09\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 7109/15878 [00:05<00:07, 1201.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'17': [16], '-': []}) ['-', '17']\n",
      "- what\n",
      "- is\n",
      "- the\n",
      "- average\n",
      "- against\n",
      "- when\n",
      "- the\n",
      "- drawn\n",
      "- is\n",
      "- more\n",
      "- than\n",
      "- 2\n",
      "- and\n",
      "- the\n",
      "- difference\n",
      "- of-\n",
      "- 17\n",
      "- and\n",
      "- a\n",
      "- played\n",
      "- smaller\n",
      "- than\n",
      "- 20\n",
      "17 what\n",
      "17 is\n",
      "17 the\n",
      "17 average\n",
      "17 against\n",
      "17 when\n",
      "17 the\n",
      "17 drawn\n",
      "17 is\n",
      "17 more\n",
      "17 than\n",
      "17 2\n",
      "17 and\n",
      "17 the\n",
      "17 difference\n",
      "17 of-\n",
      "17 17\n",
      "17 and\n",
      "17 a\n",
      "17 played\n",
      "17 smaller\n",
      "17 than\n",
      "17 20\n",
      "defaultdict(<class 'list'>, {'1035': []}) ['1035']\n",
      "1035 which\n",
      "1035 call\n",
      "1035 sign\n",
      "1035 broadcast\n",
      "1035 at\n",
      "1035 less\n",
      "1035 than\n",
      "1035 1035mhz\n",
      "1035 has\n",
      "1035 an\n",
      "1035 erp\n",
      "1035 w\n",
      "1035 of\n",
      "1035 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▋     | 7348/15878 [00:05<00:07, 1158.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'135': []}) ['135']\n",
      "135 what\n",
      "135 is\n",
      "135 the\n",
      "135 socket\n",
      "135 related\n",
      "135 to\n",
      "135 the\n",
      "135 processor\n",
      "135 released\n",
      "135 on\n",
      "135 june\n",
      "135 22\n",
      "135 2005\n",
      "135 having\n",
      "135 a\n",
      "135 frequency\n",
      "135 of\n",
      "135 1600mhz\n",
      "135 and\n",
      "135 voltage\n",
      "135 under\n",
      "135 135v\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 7576/15878 [00:06<00:07, 1107.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'a': []}) ['a']\n",
      "a during\n",
      "a the\n",
      "a tournament\n",
      "a in\n",
      "a which\n",
      "a jiří\n",
      "a novák\n",
      "a was\n",
      "a absenta\n",
      "a in\n",
      "a 1995\n",
      "a absenta\n",
      "a in\n",
      "a 1997\n",
      "a and\n",
      "a made\n",
      "a it\n",
      "a to\n",
      "a the\n",
      "a 3rd\n",
      "a round\n",
      "a 3r\n",
      "a in\n",
      "a 2003\n",
      "a how\n",
      "a did\n",
      "a he\n",
      "a do\n",
      "a in\n",
      "a 2006\n",
      "defaultdict(<class 'list'>, {'a': []}) ['a']\n",
      "a during\n",
      "a the\n",
      "a tournament\n",
      "a in\n",
      "a which\n",
      "a jiří\n",
      "a novák\n",
      "a was\n",
      "a absenta\n",
      "a in\n",
      "a 1995\n",
      "a absenta\n",
      "a in\n",
      "a 1997\n",
      "a and\n",
      "a made\n",
      "a it\n",
      "a to\n",
      "a the\n",
      "a 3rd\n",
      "a round\n",
      "a 3r\n",
      "a in\n",
      "a 2003\n",
      "a how\n",
      "a did\n",
      "a he\n",
      "a do\n",
      "a in\n",
      "a 2006\n",
      "defaultdict(<class 'list'>, {'a': []}) ['a']\n",
      "a in\n",
      "a the\n",
      "a hamburg\n",
      "a masters\n",
      "a tournament\n",
      "a during\n",
      "a which\n",
      "a jiří\n",
      "a novák\n",
      "a was\n",
      "a absenta\n",
      "a in\n",
      "a 1996\n",
      "a how\n",
      "a did\n",
      "a he\n",
      "a do\n",
      "a in\n",
      "a 2003\n",
      "defaultdict(<class 'list'>, {'a': []}) ['a']\n",
      "a in\n",
      "a the\n",
      "a tournament\n",
      "a during\n",
      "a which\n",
      "a jiří\n",
      "a novák\n",
      "a was\n",
      "a absenta\n",
      "a in\n",
      "a 2004\n",
      "a how\n",
      "a did\n",
      "a he\n",
      "a do\n",
      "a in\n",
      "a 2003\n",
      "defaultdict(<class 'list'>, {'1r': []}) ['1r']\n",
      "1r in\n",
      "1r the\n",
      "1r tournament\n",
      "1r during\n",
      "1r which\n",
      "1r jiří\n",
      "1r novák\n",
      "1r made\n",
      "1r it\n",
      "1r to\n",
      "1r the\n",
      "1r 1st\n",
      "1r round1r\n",
      "1r in\n",
      "1r 1995\n",
      "1r how\n",
      "1r did\n",
      "1r he\n",
      "1r do\n",
      "1r in\n",
      "1r 2001\n",
      "defaultdict(<class 'list'>, {'a': []}) ['a']\n",
      "a during\n",
      "a the\n",
      "a hamburg\n",
      "a masters\n",
      "a tournament\n",
      "a during\n",
      "a which\n",
      "a jiří\n",
      "a novák\n",
      "a was\n",
      "a absenta\n",
      "a in\n",
      "a 1998\n",
      "a how\n",
      "a did\n",
      "a he\n",
      "a do\n",
      "a in\n",
      "a 1997\n",
      "defaultdict(<class 'list'>, {'antonio': [12], 'davis': [13], '12': []}) ['antonio', 'davis', '12']\n",
      "antonio what\n",
      "antonio is\n",
      "antonio the\n",
      "antonio score\n",
      "antonio for\n",
      "antonio the\n",
      "antonio game\n",
      "antonio less\n",
      "antonio than\n",
      "antonio 21\n",
      "antonio and\n",
      "antonio of\n",
      "antonio antonio\n",
      "antonio davis\n",
      "antonio 12had\n",
      "antonio the\n",
      "antonio high\n",
      "antonio rebounds\n",
      "davis what\n",
      "davis is\n",
      "davis the\n",
      "davis score\n",
      "davis for\n",
      "davis the\n",
      "davis game\n",
      "davis less\n",
      "davis than\n",
      "davis 21\n",
      "davis and\n",
      "davis of\n",
      "davis antonio\n",
      "davis davis\n",
      "davis 12had\n",
      "davis the\n",
      "davis high\n",
      "davis rebounds\n",
      "12 what\n",
      "12 is\n",
      "12 the\n",
      "12 score\n",
      "12 for\n",
      "12 the\n",
      "12 game\n",
      "12 less\n",
      "12 than\n",
      "12 21\n",
      "12 and\n",
      "12 of\n",
      "12 antonio\n",
      "12 davis\n",
      "12 12had\n",
      "12 the\n",
      "12 high\n",
      "12 rebounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 8167/15878 [00:06<00:06, 1172.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'2049': []}) ['2049']\n",
      "2049 what\n",
      "2049 is\n",
      "2049 the\n",
      "2049 average\n",
      "2049 sales\n",
      "2049 for\n",
      "2049 the\n",
      "2049 company\n",
      "2049 with\n",
      "2049 market\n",
      "2049 value\n",
      "2049 of\n",
      "2049 2049bil\n",
      "2049 and\n",
      "2049 profits\n",
      "2049 under\n",
      "2049 206bil\n",
      "defaultdict(<class 'list'>, {'206': []}) ['206']\n",
      "206 what\n",
      "206 is\n",
      "206 the\n",
      "206 average\n",
      "206 sales\n",
      "206 for\n",
      "206 the\n",
      "206 company\n",
      "206 with\n",
      "206 market\n",
      "206 value\n",
      "206 of\n",
      "206 2049bil\n",
      "206 and\n",
      "206 profits\n",
      "206 under\n",
      "206 206bil\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 9022/15878 [00:07<00:05, 1226.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'3,616': []}) ['3,616']\n",
      "3,616 what\n",
      "3,616 is\n",
      "3,616 the\n",
      "3,616 total\n",
      "3,616 population\n",
      "3,616 for\n",
      "3,616 the\n",
      "3,616 3,616km\n",
      "3,616 area\n",
      "defaultdict(<class 'list'>, {'12,241': []}) ['12,241']\n",
      "12,241 what\n",
      "12,241 is\n",
      "12,241 the\n",
      "12,241 lowest\n",
      "12,241 population\n",
      "12,241 2011\n",
      "12,241 for\n",
      "12,241 the\n",
      "12,241 community\n",
      "12,241 with\n",
      "12,241 an\n",
      "12,241 area\n",
      "12,241 of\n",
      "12,241 12,241km2\n",
      "12,241 and\n",
      "12,241 a\n",
      "12,241 density\n",
      "12,241 inhabitants/km\n",
      "12,241 2\n",
      "12,241 smaller\n",
      "12,241 than\n",
      "12,241 211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 9537/15878 [00:07<00:05, 1265.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'71': [14], 'dead': [16], 'link': [17]}) ['71', 'dead', 'link']\n",
      "71 what\n",
      "71 is\n",
      "71 name\n",
      "71 when\n",
      "71 goals\n",
      "71 is\n",
      "71 80\n",
      "71 and\n",
      "71 when\n",
      "71 club\n",
      "71 source\n",
      "71 i\n",
      "71 \n",
      "71 is\n",
      "71 71\n",
      "71 \n",
      "71 dead\n",
      "71 link\n",
      "71 \n",
      "dead what\n",
      "dead is\n",
      "dead name\n",
      "dead when\n",
      "dead goals\n",
      "dead is\n",
      "dead 80\n",
      "dead and\n",
      "dead when\n",
      "dead club\n",
      "dead source\n",
      "dead i\n",
      "dead \n",
      "dead is\n",
      "dead 71\n",
      "dead \n",
      "dead dead\n",
      "dead link\n",
      "dead \n",
      "link what\n",
      "link is\n",
      "link name\n",
      "link when\n",
      "link goals\n",
      "link is\n",
      "link 80\n",
      "link and\n",
      "link when\n",
      "link club\n",
      "link source\n",
      "link i\n",
      "link \n",
      "link is\n",
      "link 71\n",
      "link \n",
      "link dead\n",
      "link link\n",
      "link \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 13450/15878 [00:10<00:01, 1238.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'35666': []}) ['35666']\n",
      "35666 what\n",
      "35666 is\n",
      "35666 the\n",
      "35666 average\n",
      "35666 population\n",
      "35666 of\n",
      "35666 the\n",
      "35666 township\n",
      "35666 having\n",
      "35666 land\n",
      "35666 of\n",
      "35666 35666sqmi\n",
      "35666 and\n",
      "35666 geo\n",
      "35666 id\n",
      "35666 over\n",
      "35666 3807364500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 14303/15878 [00:11<00:01, 1181.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'/b/': [8], '/ɸ/;': []}) ['/ɸ/;', '/b/']\n",
      "/ɸ/; which\n",
      "/ɸ/; gothic\n",
      "/ɸ/; letter\n",
      "/ɸ/; has\n",
      "/ɸ/; proto-germanic\n",
      "/ɸ/; origin\n",
      "/ɸ/; of\n",
      "/ɸ/; /ɸ/\n",
      "/ɸ/; /b/\n",
      "/b/ which\n",
      "/b/ gothic\n",
      "/b/ letter\n",
      "/b/ has\n",
      "/b/ proto-germanic\n",
      "/b/ origin\n",
      "/b/ of\n",
      "/b/ /ɸ/\n",
      "/b/ /b/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 14955/15878 [00:12<00:00, 1287.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'18': []}) ['18']\n",
      "18 what\n",
      "18 team\n",
      "18 does\n",
      "18 tariq\n",
      "18 kirksay\n",
      "18 a\n",
      "18 guard\n",
      "18 who\n",
      "18 is\n",
      "18 taller\n",
      "18 than\n",
      "18 18m\n",
      "18 and\n",
      "18 born\n",
      "18 before\n",
      "18 1982\n",
      "18 represent\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15878/15878 [00:12<00:00, 1227.29it/s]\n"
     ]
    }
   ],
   "source": [
    "test_set = WikiSQLDataset(type='test', model=model)\n",
    "test_loader = DataLoader(test_set, batch_size=32)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "question_1 = test_set[0]['input'][0]\n",
    "question_2 = test_set[1]['input'][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "question_3 = 'If % lunsford is 51.82% what is the % mcconnell in Letcher?'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "where_answer_1 = \"Terrence Ross\"\n",
    "where_answer_2 = \"1995-96\"\n",
    "where_answer_3 = \"51.82%\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "['What', 'is', 'terrence', \"ross'\", 'nationality']"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_1.split()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "['What', 'clu', 'was', 'in', 'toronto', '1995-96']"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_2.split()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "\"What is terrence ross' nationality\""
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import re"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "pattern_list = [r'(?i)\\b\\w*terrence\\w*\\b', r'(?i)\\b\\w*ross\\w*\\b']"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "[2, 3]"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pattern_list = [r'(?i)\\b\\w*sustainabl\\w*\\b', r'(?i)\\b\\w*suppl\\w*\\b', r'(?i)\\b\\w*fashion\\w*\\b']\n",
    "index_list = []\n",
    "for pattern in pattern_list:\n",
    "    for idx, token in enumerate(question_1.split()):\n",
    "        if re.findall(pattern, token):\n",
    "            index_list.append(idx)\n",
    "index_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "map_list = [index_list[0], index_list[-1]-index_list[0]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "[2, 1]"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_list"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "def try_generate_mapping(question_token_list, pattern_list, gt):\n",
    "    index_list = []\n",
    "    for pattern, key in zip(pattern_list, gt):\n",
    "        for idx, token in enumerate(question_token_list):\n",
    "            if (re.findall(pattern, token)) or (key==token):\n",
    "                index_list.append(idx)\n",
    "    return [index_list[0], index_list[-1]-index_list[0]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "[2, 1]"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_generate_mapping(question_1.split(), pattern_list, where_answer_1.split())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "[5, 0]"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_generate_mapping(question_2.split(), [r'(?i)\\b\\w*1995-96\\w*\\b'], where_answer_2.split())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "['Terrence', 'Ross']"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "where_answer_1.split()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "['(?i)\\\\b\\\\w*terrence\\\\w*\\\\b', '(?i)\\\\b\\\\w*ross\\\\w*\\\\b']"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[fr'(?i)\\b\\w*{token.lower()}\\w*\\b' for token in where_answer_1.split()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "[2, 1]"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_generate_mapping(question_1.split(), [fr'(?i)\\b\\w*{token.lower()}\\w*\\b' for token in where_answer_1.split()], where_answer_1.split())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "[5, 0]"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_generate_mapping(question_2.split(), [fr'(?i)\\b\\w*{token.lower()}\\w*\\b' for token in where_answer_2.split()], where_answer_2.split())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "[4, 0]"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "try_generate_mapping(question_3.split(), [fr'(?i)\\b\\w*{token.lower()}\\w*\\b' for token in where_answer_3.split()], where_answer_3.split())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "{'table_id': '1-10015132-16',\n 'columns': 'Player, No., Nationality, Position, Years in Toronto, School/Club Team',\n 'input': (\"What is terrence ross' nationality\",\n  'Player, No., Nationality, Position, Years in Toronto, School/Club Team'),\n 'tokenized_inputs': {'question': {'input_ids': tensor([  101,  2054,  2003, 25170,  5897,  5811,  1005, 10662,  2447,  1010,\n           2053,  1012,  1010, 10662,  1010,  2597,  1010,  2086,  1999,  4361,\n           1010,  2082,  1013,  2252,  2136,   102,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0])},\n  'columns': {'input_ids': tensor([  101,  2447,  1010,  2053,  1012,  1010, 10662,  1010,  2597,  1010,\n           2086,  1999,  4361,  1010,  2082,  1013,  2252,  2136,   102,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0])}},\n 'labels': {'sel': 2,\n  'agg': 0,\n  'conds': (1, [0, 0, 0, 0], [1, 0, 0, 0], [[2, 2], [0, 0], [0, 0], [0, 0]])},\n 'CHECK': (['Terrence Ross'], ['terrence ross'])}"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "cond_range = test_set[0]['labels']['conds'][3][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "cleaned_q = list(WikiSQLDataset._generate_cond3(test_set[0]['input'][0].split()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "\"What is terrence ross' nationality\""
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[0]['input'][0]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "['what', 'is', 'terrence', \"ross'\", 'nationality']"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_q"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "['terrence', \"ross'\"]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_q[cond_range[0]:cond_range[0]+cond_range[1]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "{'table_id': '1-10015132-16',\n 'columns': 'Player, No., Nationality, Position, Years in Toronto, School/Club Team',\n 'input': ('What clu was in toronto 1995-96',\n  'Player, No., Nationality, Position, Years in Toronto, School/Club Team'),\n 'tokenized_inputs': {'question': {'input_ids': tensor([  101,  2054, 18856,  2226,  2001,  1999,  4361,  2786,  1011,  5986,\n           2447,  1010,  2053,  1012,  1010, 10662,  1010,  2597,  1010,  2086,\n           1999,  4361,  1010,  2082,  1013,  2252,  2136,   102,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n          1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0])},\n  'columns': {'input_ids': tensor([  101,  2447,  1010,  2053,  1012,  1010, 10662,  1010,  2597,  1010,\n           2086,  1999,  4361,  1010,  2082,  1013,  2252,  2136,   102,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n              0,     0]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n          0, 0, 0, 0, 0, 0, 0, 0])}},\n 'labels': {'sel': 5,\n  'agg': 0,\n  'conds': (1, [4, 0, 0, 0], [1, 0, 0, 0], [[5, 1], [0, 0], [0, 0], [0, 0]])},\n 'CHECK': (['1995-96'], ['1995-96'])}"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set[1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can I Love? -- can i love -- Which examples ask the existential question \"Can I Love?\"\n",
      "\"Ambush\" (Part 1) -- ambush (part 1) -- Who is the writer of the episode called \"Ambush\" (part 1)?\n",
      "bumped St. Catharine's -- bumped st. catharine --  how many 1st day with 3rd day being bumped st. catharine's\n",
      "\" Save the Last Dance for Me \" -- save the last dance for me --  how many artbeingt with song title being \" save the last dance for me \"\n",
      "428650 -- $428650 -- What purses had a winners share equal to $428650?\n",
      "M. Van der Goten ( BEL ) --  -- Name the 3 where weightlifter is m. van der goten ( bel )\n",
      "\"Breakthrough\" \"Burēku surū\" (ブレーク·スルー) -- breakthrough burēku surū (ブレーク·スルー) -- What is the number of theWhat is the number of the chapter that is called \"breakthrough\" \"burēku surū\" (ブレーク·スルー)?\n",
      "\"Takeback\" \"Tēkubakku\" (テークバック) -- takeback tēkubakku (テークバック) -- Which are dates of transmission in English of the title \"takeback\" \"tēkubakku\" (テークバック)\n",
      "\"One to Go\" (Part 2) -- one to go (part 2) -- What is every \"directed by\" when the title is \"One To Go\" (part 2)?\n",
      "307 VS. -- 307 vs -- which episode was Transmitted on wednesday if the episode of \"307 vs.\" was transmitted on friday?  \n",
      "Bill Finger Edmond Hamilton Dick Sprang , et al. -- bill finger edmond hamilton dick sprang , et al -- Name the # for bill finger edmond hamilton dick sprang , et al.\n",
      "思 sī, \"thought\" -- 思 sī, thought -- What is the intelligence os the one that has 思 sī, \"thought\"?\n",
      "376 -- $376 -- How much was spent in 1949/50 (in $ millions) in the country where the cumulative expenditure is $376 millions?\n",
      "59 -- $59 -- What country spent $59 millions in 1949/50?\n",
      "232 -- 232$ -- What's the 1949/50 expenditure (in $ millions) in the country where the 1948/49 expenditure was 232$ millions?\n",
      "921 -- $921 -- What's the 1948/49 expenditure (in $ millions) in the country whose 1949/50 expenditure is $921 millions?\n",
      "59 -- 59% -- What is the minimum length of the locations where the average climb percentage is exactly 59%?\n",
      "Baccalaureate college --  -- What was the enrollment (2005) for baccalaureate colleges , for Granite State College?\n",
      "470,000 -- $470,000 -- How many times could you earn $470,000 as the grand prize?\n",
      "0 - 1 Barbiero 78' -- 0 - 1 barbiero 78 -- When 0 - 1 barbiero 78' is the score how many measurements of attendance are there?\n",
      "3 - 1 Hughes 64' -- 3 - 1 hughes 64 -- When 3 - 1 hughes 64' is the score what is the stadium?\n",
      "1 - 1 Leckie 90+3' -- 1 - 1 leckie 90+3 -- When 1 - 1 leckie 90+3' is the score what is the stadium?\n",
      "Pokémon ieru kana? BW -- pokémon ieru kana bw -- When  pokémon ieru kana? bw is the romaji who is the vocalist?\n",
      "K. Annamalai -- k. annamalai´s -- which was k. annamalai´s party a?\n",
      "\"Kärleken vänder allt\" (The love turns everything) -- kärleken vänder allt (the love turns everything) -- What is the position of \"kärleken vänder allt\" (the love turns everything)?\n",
      "\"Kärleken vänder allt\" (The love turns everything) -- kärleken vänder allt (the love turns everything) -- What is the position of \"kärleken vänder allt\" (the love turns everything)?\n",
      "Madison Square Garden ( New York City, New York ) --  -- When madison square garden ( new york city, new york ) is the tournament venue (city) what is the conference tournament?\n",
      "\"Southwestern Exposure\", a twelve-egg omelette -- southwestern exposure, a twelve-egg omelette -- What is the original airdate of the episode where the challenge is \"Southwestern Exposure\", a twelve-egg omelette\"?\n",
      "\" Old Friend \" -- old friend -- Who directed the episode with a title of \" old friend \"?\n",
      "7.56 -- 7.56. -- Title is the total number where u.s. viewers (million) is 7.56.\n",
      "Adderly Fong ( 2013 ) -- adderly fong ( 2013 -- How many times is last/current driver(s) 3 november 2013 is adderly fong ( 2013 )?\n",
      "Marlon Stöckinger , Kotaro Sakurai ( 2011 ) -- marlon stöckinger , kotaro sakurai ( 2011 -- Who is the last/current driver(s) 3 november 2013 when first driver(s) is marlon stöckinger , kotaro sakurai ( 2011 )?\n",
      "Daniel Abt ( 2012 ) -- daniel abt ( 2012 -- What is the country when last/current driver(s) 3 november 2013 is daniel abt ( 2012 )?\n",
      "[[|]] 4 points -- [[|]] 6 points -- What was the final venue whene England hasted the competition and the runner-up record is [[|]] 4 points and the winner record is [[|]] 6 points?\n",
      "21 -- 2006-06-21 -- Tell me the average spectators for 2006-06-21 and time more than 21\n",
      "75 -- 75% -- What are the fewest losses for a player lower than 3, with wins fewer than 75%, 0 draws and 56 points?\n",
      "100 -- 100% -- What is the smallest draws for a player larger than 2 with a 100% wins?\n",
      "56.15 -- 56.15% -- What is the average draws for a player larger than 16 with more than 1 tries and a win percentage smaller than 56.15%?\n",
      "tony o'sullivan --  -- What is Tony O'Sullivan's county?\n",
      "50,000 -- $50,000 -- What was the score for the tournament that had a winner's share of $50,000?\n",
      "28,000 -- $28,000 -- What date was the tournament that had a winner's share of $28,000?\n",
      "530,808 -- $530,808 -- Add up all the events whose earnings is less than $530,808, have less than 2 wins and is ranked lower than 5.\n",
      "44 -- 44+ -- What is the shot % with a 44+ Ends Lost, skip Cathy King, and smaller than 13 Black Ends?\n",
      "6,028,927 -- $6,028,927 -- What is the lowest number of wins for tom watson who is ranked larger than number 1 and makes more than $6,028,927?\n",
      "60,000-->58,000 koku -- 60,000--58,000 koku -- What is the tenure of the person with revenues of 60,000-->58,000 koku?\n",
      "– --  -- Which League that has no playoffs in the Year of 2008–09?\n",
      "10 -- top-10 -- Name the average top-10 for cuts made of 10 and top-25 more than 6\n",
      "14 -- 14% -- Which track in Austria has Bobsleigh-skeleton curves with a grade of 14%?\n",
      "15 -- 15% -- What is the shortest length of a track in Norway that has a maximum grade of 15% and a vertical drop less than 122.22 m?\n",
      "5.22 -- 5.22. -- Tell me the record for a time in seconds smaller than 5.22.\n",
      "katee shean stephen \"twitch\" boss -- katee shean stephen twitch boss -- What is Choreographer(s), when Chosen By is Mary Murphy, and when Couple is Katee Shean Stephen \"Twitch\" Boss?\n",
      "10 -- top-10 -- What was the highest Top-10, when the Top-5 was greater than 3, when the Cuts made were 20, and when the Top-25 was more than 10?\n",
      "- 17 --  -- What is the average Against when the drawn is more than 2 and the Difference of- 17, and a Played smaller than 20?\n",
      "42 m. -- 42 m -- What is the year built of the home with a built status and a 42 m. height?\n",
      "42 m. -- 42 m -- What is the highest number of stories in homes with a height of 42 m.?\n",
      "the three pintos (die drei pintos) -- the conductor of the three pintos -- Who was the Conductor of the Three Pintos (Die Drei Pintos) Production?\n",
      "103.5 --  -- Which call sign, broadcast at less than 103.5MHz, has an ERP W of 50?\n",
      "1.35 --  -- What is the socket related to the processor released on June 22, 2005, having a frequency of 1600MHz and voltage under 1.35V?\n",
      "sky cinema + sky hd -- sky cinema passion hd -- What is HDTV, when Content is Cinema, when Package/Option is Sky Cinema + Sky HD, and when Television Service is Sky Cinema Passion HD?\n",
      "118 -- 118% -- How many people live where there are 118% of people have phones?\n",
      "a --  -- During the Tournament in which Jiří Novák was absent(A) in 1995, absent(A) in 1997, and made it to the 3rd round (3R) in 2003, how did he do in 2006?\n",
      "a --  -- During the Tournament in which Jiří Novák was absent(A) in 1995, absent(A) in 1997, and made it to the 3rd round (3R) in 2003, how did he do in 2006?\n",
      "3r -- (3r) -- During the Tournament in which Jiří Novák was absent(A) in 1995, absent(A) in 1997, and made it to the 3rd round (3R) in 2003, how did he do in 2006?\n",
      "a --  -- In the Hamburg Masters Tournament, during which Jiří Novák was absent(A) in 1996, how did he do in 2003?\n",
      "a --  -- In the Tournament during which Jiří Novák was absent(A) in 2004, how did he do in 2003?\n",
      "1r --  -- In the Tournament during which Jiří Novák made it to the 1st round(1R) in 1995, how did he do in 2001?\n",
      "a --  -- During the Hamburg Masters Tournament, during which Jiří Novák was absent(A) in 1998, how did he do in 1997?\n",
      "1975? -- 1975 -- What is the resurrection of 144,000 date with a start of Christ's presence date in 1914, a separation of sheep & goats during Christ's presence, and a great tribulation date in 1975?\n",
      "players' -- players -- Which 2007–08 event has 2008–09 of dnp and an Event of players'?\n",
      "antonio davis (12) --  -- What is the Score for the Game less than 21, and of antonio davis (12)had the High rebounds?\n",
      "amy macdonald ( mr rock & roll ) -- amy macdonald ( mr rock & roll -- WHich Coat of Cash\" Wearing Celebrity has a Episode Number larger than 1 and with amy macdonald ( mr rock & roll )?\n",
      "204.9 --  -- What is the average sales for the company with market value of 204.9bil and profits under 20.6bil?\n",
      "20.6 --  -- What is the average sales for the company with market value of 204.9bil and profits under 20.6bil?\n",
      "5,000 -- $5,000 -- What was the score of the player who earned $5,000?\n",
      "9,000 -- $9,000 -- What country is the player who earned $9,000 from?\n",
      "#154 -- 154 -- What is the NHL team for Round 5 and an overall ranking of #154?\n",
      "#195 -- 195 -- Who is the player on round 7 with an overall ranking of #195?\n",
      "24,542 -- $24,542 -- What is the score of the United States, which has more than $24,542?\n",
      "3,616 --  -- What is the total population for the 3,616km area?\n",
      "200 mhz -- 200 mhz -- Which Multiplier has a Front Side Bus of 200 mhz, and a Frequency of 1200 mhz?\n",
      "1200 mhz -- 1200 mhz -- Which Multiplier has a Front Side Bus of 200 mhz, and a Frequency of 1200 mhz?\n",
      "1333 mhz -- 1333 mhz -- Which L2-Cache has a Frequency of 1333 mhz, and a Model Number of c3 1.3a?\n",
      "1.4 v -- 1.4 v -- Which Front Side Bus has a Voltage of 1.4 v, and a Frequency of 1333 mhz?\n",
      "1333 mhz -- 1333 mhz -- Which Front Side Bus has a Voltage of 1.4 v, and a Frequency of 1333 mhz?\n",
      "12,241 --  -- What is the lowest population (2011) for the community with an Area of 12,241km2 and a Density (inhabitants/km 2) smaller than 21.1?\n",
      "currie cup \"b\" section -- currie cup b section -- What was the sum of the numbers listed under against when currie cup \"b\" section was the opposing team?\n",
      "all times are in eastern. -- all times are in eastern -- What is Site, when Opponent is \"All times are in eastern.\"?\n",
      "11 -- 2010-11 -- What is the sum of 2010-11 when the rank is greater than 11?\n",
      "71 [ dead link ] --  -- What is Name, when Goals is \"80\", and when Club Source [I ] is \"71 [ dead link ]\"?\n",
      "#7 -- 7 -- When was the premiere of the show that had a rank of #7?\n",
      "ba'ath party ( syria region ) -- ba'ath party ( syria region -- What is Left Office, when Political Party is Ba'ath Party ( Syria Region ), and when Took Office is 7 March 1958?\n",
      "\" the doctor dances \" -- the doctor dances -- Which Original airdate (UK) has a Doctor Who episode of \" the doctor dances \"?\n",
      "moved to run a farm with boyfriend jake. -- moved to run a farm with boyfriend jake -- What is Number Of Episodes, when Notes is \"Moved to run a farm with boyfriend Jake.\"?\n",
      "0.625 -- 0.625% -- What is the low loss total for teams with under 3 years and a less than 0.625% winning percentage?\n",
      "500,000 -- $500,000 -- What is average prize for first place with a $500,000 purse in the Franklin Quest Championship?\n",
      "analog -- digital/analog -- What is the Retail name with a Digital/analog signal with analog, and a Chipset based on with radeon 9600?\n",
      "1,579,988 -- $1,579,988 -- What's the wins with less than 27 events and earnings of $1,579,988?\n",
      "10\" x 15\" -- 10 x 15 -- What is the wheel arrangement for the model with 10\" x 15\" cylinders?\n",
      "10 -- 10,with -- What is the highest +1d12 (6) with a 3d6 or 1d20 Resolution (+10) larger than 10,with a +1d6-1d6 or +1d10-1d10 (+0) of 4, with 1d10 Resolution (+5) larger than 9?\n",
      "* dane -- dane -- What is the population (hab) when the distance medellin downtown (km) is * dane?\n",
      "+ 1:39.591 -- 1:39.591 -- How many laps are associated with a time of + 1:39.591?\n",
      "+ 4 laps -- 4 laps -- I want the total number of Laps for time/retired for + 4 Laps and grid more than 20\n",
      "us 83 bus. -- us 83 bus -- What is the length of the highway with junctions i-35 us 83 and named us 83 bus.?\n",
      "997 -- 997,more -- Which name has an Order smaller than 997,more than 5 goals, and 215 games?\n",
      "+ 4 laps -- 4 laps -- How many laps have a Time/Retired of + 4 laps, and a Driver of graham hill?\n",
      "||54,918||50–36 -- occur -- On what date did a save of ||54,918||50–36 occur?\n",
      "||25,354||63–43 -- occurred -- What was the score when a save of ||25,354||63–43 occurred?\n",
      "2,708,005 -- $2,708,005 -- What is the highest rank of the player who played 30 events and made less than $2,708,005?\n",
      "0.2 -- 2 -- What's the total long for an avg/g over 0.2, fewer than 2 loss, and a gain less than 8?\n",
      "10 + 10 + 10 = 30 -- 10 + 10 = 30 -- What Date performed has a Scores by each individual judge of 10 + 10 + 10 = 30, and a Main contestant of karanvir bohra?\n",
      "sc -- (sc/st/none) -- Which Number of electorates (2009) has a District of jhajjar, and a Reserved for (SC/ST/None) of sc, and a Constituency number smaller than 66?\n",
      "liu yang ( hkg ) -- liu yang ( hkg -- What is the lowest Jianshu number for Liu Yang ( hkg )?\n",
      "richard devine ( gbr ) -- richard devine ( gbr -- What is the lowest rank when Jianshu is smaller than 9.66, for Richard Devine ( gbr ), with a total smaller than 19.02?\n",
      "nguyen huy thanh ( vie ) -- nguyen huy thanh ( vie -- What is the number of Jianshu when the total is more than 19.16, for Nguyen Huy Thanh ( vie ), and Qiangshu is more than 9.66?\n",
      "none -- /none -- Name the Number of electorates (2009 which has a Reserved for ( SC / ST /None) of none, and a Name of jahanabad?\n",
      "none -- /none -- What is the name for Nagpur district, with a reserved for ( SC / ST /None) of none, and a Constituency number of 59?\n",
      "0.406 -- 0.406% -- What is the All Home with less than 0.406% All Games?\n",
      "bf.109g-2 \"yellow 2\" -- bf.109g-2 yellow 2 -- What was the Soviet Unit when the Enemy Aircraft was bf.109g-2 \"yellow 2\"?\n",
      "bf.109g-? w.nr.? -- bf.109g- w.nr. -- What was the date of the victory when the Soviet Unit was 73 giap, and the Enemy Aircraft was bf.109g-? w.nr.?\n",
      "luftwaffe (**) -- luftwaffe -- What was the aircraft flown when the axis unit was luftwaffe (**) and the enemy aircraft was ju.88?\n",
      "yak-1b \"white 23\" -- yak-1b white 23 -- What is the axis unit of the aircraft yak-1b \"white 23\", flown on 19.07.1943?\n",
      "450 -- $450 -- Which player has $450 and a score of 76-74-74-72=296?\n",
      "82 -- $82 -- Which ranking has money of $82 and Al Watrous as the player?\n",
      "0+1 -- 1 -- What Rd 3 has a Rd 2 1 of 0+1?\n",
      "35.666 --  -- What is the average population of the township having land of 35.666sqmi and GEO ID over 3807364500?\n",
      "kōhei uchimura ( jpn ) -- kōhei uchimura ( jpn -- what is the average b score when the gymnast is kōhei uchimura ( jpn )?\n",
      "waldemar 27 -- waldemar 27´s -- What is the result of Waldemar 27´s freestyle test?\n",
      "/ɸ/; /b/ --  -- Which Gothic Letter has Proto-Germanic origin of /ɸ/; /b/?\n",
      "3,600 -- $3,600 -- What is the score for the player who won $3,600?\n",
      "ថ្ងៃអាទិត្យ [tŋaj ʔaatɨt ] -- ថ្ងៃអាទិត្យ [tŋaj ʔaatɨt -- What is the result of Saturday that's ថ្ងៃអាទិត្យ [tŋaj ʔaatɨt ] on Sunday?\n",
      "7\" single -- 7 single -- What was the catalog of the 7\" single in France?\n",
      "12\" maxi -- 12 maxi -- Where was the 12\" maxi in September 1990?\n",
      "'take away, remove' -- take away, remove -- What is the imperfect stem of the word that means 'take away, remove'?\n",
      "guard -- (guard) -- When was tony parker (guard) born?\n",
      "1.8 --  -- What team does tariq kirksay, a guard who is taller than 1.8M and born before 1982, represent?\n",
      "89.1 -- 89.1,rape -- Which aggravated assault has the highest amount and the following criteria: crime rate per 1000 greater than 89.1,rape value of 23, and a crime index greater than 1590?\n",
      "\"mv\"; converted from steam stock, 1927 -- mv; converted from steam stock, 1927 -- Bldr of mcw&f, and a Notes of \"mv\"; converted from steam stock, 1927, and a Year of 1920, and a LT Nos of 9716-9718 has what type?\n",
      "don't stop movin' -- don't stop movin -- What is the highest position less than 7 that had more than 421,760 in sales for the song Don't Stop Movin'?\n",
      "5 -- 5% -- Which country has more than 5% change in a year with a rank of 10?\n"
     ]
    },
    {
     "data": {
      "text/plain": "139"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for test in test_set:\n",
    "    for gt, pred in zip(test['CHECK'][0], test['CHECK'][1]):\n",
    "        if str(gt).lower().strip('\"') != str(pred).lower():\n",
    "            print(f'{gt} -- {pred} -- {test[\"input\"][0]}')\n",
    "            count += 1\n",
    "count"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "0.8754251165134147"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count/len(test_set)*100"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "q = 'What number game had a high assist of lebron james (7) and high point of lebron james (21)?'\n",
    "cond = 'LeBron James (7)'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def _clean_text(text):\n",
    "    char_list = '?\"()+,$[]{};*'\n",
    "    for char in char_list:\n",
    "        text = text.replace(char, '')\n",
    "    text = text.replace(\"'s\", '')\n",
    "    text = text.replace(\"'\", '')\n",
    "    return text.lower()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "def _generate_mapping(question_token_list, pattern_list, gt):\n",
    "    token_dict = defaultdict(list)\n",
    "    for pattern, key in zip(pattern_list, gt):\n",
    "        for idx, token in enumerate(question_token_list):\n",
    "            if len(key) == 1:\n",
    "                if key.lower() == _clean_text(token):\n",
    "                    token_dict[key].append(idx)\n",
    "            else:\n",
    "                if (re.findall(pattern, _clean_text(token))) or \\\n",
    "                            (key.lower() == _clean_text(token)) or \\\n",
    "                            ((re.findall(r'^[-+]?(?:[0-9]+,)*[0-9]+(?:\\.[0-9]+)?$', key)) and\n",
    "                            (re.findall(r'^[-+]?(?:[0-9]+,)*[0-9]+(?:\\.[0-9]+)?$', _clean_text(token))) and\n",
    "                            (float(_clean_text(token)) == float(_clean_text(key)))):\n",
    "                    token_dict[key].append(idx)\n",
    "    first_tokens = set(token_dict[gt[0]])\n",
    "    end_tokens = set(token_dict[gt[-1]])\n",
    "    for end in end_tokens:\n",
    "        for start in first_tokens:\n",
    "            if (end -start + 1) == len(gt):\n",
    "                index_list = [start, end]\n",
    "    return [index_list[0], index_list[-1] - index_list[0] + 1]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "pattern = [fr'(?i)\\b\\w*{token.lower()}\\w*\\b' for token in _clean_text(str(cond)).split()]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "[8, 3]"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_generate_mapping(q.split(), pattern, _clean_text(str(cond)).split())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "txt = \"Washington Capital's\""
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt.endswith(\"'s\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "'Washington Capital'"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r\"'s\", '', txt)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "['washington', \"capital's\"]"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(WikiSQLDataset._generate_cond3(txt.split()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "'Washington Capital'"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WikiSQLDataset._digitize(txt.strip(\",\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "\"Washington Capital's\""
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(txt.split())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
