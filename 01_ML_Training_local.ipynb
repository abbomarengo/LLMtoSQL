{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from llmtosql.model import WikiSQLModel\n",
    "from llmtosql.trainer import Trainer\n",
    "from llmtosql.dataloader import WikiSQLDataset\n",
    "from llmtosql.utils.utils import plot_history, load_model, load_history\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "# os.environ['PYTORCH_ENABLE_MPS_FALLBACK']='1'\n",
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/albertomerango/Coeuraj/v_env\n"
     ]
    }
   ],
   "source": [
    "print(os.environ[\"VIRTUAL_ENV\"])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "path = '../WikiSQL/data/dev.jsonl'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "train_set =  WikiSQLDataset(type='dev')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# val_set = WikiSQLDataset(type='dev')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "8421"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set.data)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# datasets = (train_set, val_set)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = WikiSQLModel(base_model_type='bert-base-cased')\n",
    "try:\n",
    "    model = load_model(model, 'model_output/model.pth')\n",
    "except:\n",
    "    print('No model loaded')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "config = {\n",
    "    'seed': 32,\n",
    "    'scheduler': None,\n",
    "    'optimizer': 'adam',\n",
    "    'momentum': 0.9,\n",
    "    'weight_decay': 0.0,\n",
    "    'lr': 0.001,\n",
    "    'criterion': 'cross_entropy',\n",
    "    'metric': 'accuracy',\n",
    "    'pred_function': 'softmax',\n",
    "    'model_dir': 'model_output',\n",
    "    'backend': 'smddp'\n",
    "}"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-25 18:45.06 [info     ] Config inputs.                 config={'seed': 32, 'scheduler': None, 'optimizer': 'adam', 'momentum': 0.9, 'weight_decay': 0.0, 'lr': 0.001, 'criterion': 'cross_entropy', 'metric': 'accuracy', 'pred_function': 'softmax', 'model_dir': 'model_output', 'backend': 'smddp'}\n",
      "2023-02-25 18:45.06 [info     ] Loading the model.\n",
      "2023-02-25 18:45.06 [info     ] Training on device: cpu.\n",
      "2023-02-25 18:45.06 [info     ] Loading training and validation set.\n",
      "2023-02-25 18:45.06 [info     ] Preparing the data.\n",
      "2023-02-25 18:45.06 [debug    ] Processes 8421/8421 (100%) of train data\n",
      "2023-02-25 18:45.06 [debug    ] Processes 8421/8421 (100%) of validation data\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, datasets=train_set, epochs=6, batch_size=16, is_parallel=False, **config)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-25 18:45.06 [info     ] Start training..\n",
      "2023-02-25 18:45.06 [info     ] ------------------------------ EPOCH 1 / 6 ------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 527/527 [2:18:27<00:00, 15.76s/batch, loss=34.8, metric=0.148]   \n",
      "100%|██████████| 527/527 [2:04:41<00:00, 14.20s/batch, loss=17.9, metric=0.161]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-02-25 23:08.15 [info     ] Saving the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory model_output does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn [11], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Models/LLMtoSQL/llmtosql/trainer.py:265\u001B[0m, in \u001B[0;36mfit\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclear()\n\u001B[1;32m    264\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvalidate:\n\u001B[0;32m--> 265\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_one_epoch()\n\u001B[1;32m    266\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclear()\n\u001B[1;32m    267\u001B[0m \u001B[38;5;66;03m# Save model on master node.\u001B[39;00m\n",
      "File \u001B[0;32m~/Models/LLMtoSQL/llmtosql/trainer.py:244\u001B[0m, in \u001B[0;36msave_model\u001B[0;34m(self, model_dir)\u001B[0m\n\u001B[1;32m    242\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mval_losses\u001B[38;5;241m.\u001B[39mappend(val_loss)\n\u001B[1;32m    243\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmetric:\n\u001B[0;32m--> 244\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mval_metrics\u001B[38;5;241m.\u001B[39mappend(running_metric \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mval_loader))\n\u001B[1;32m    245\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m running_metric\n",
      "File \u001B[0;32m~/Coeuraj/v_env/lib/python3.9/site-packages/torch/serialization.py:422\u001B[0m, in \u001B[0;36msave\u001B[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001B[0m\n\u001B[1;32m    419\u001B[0m _check_dill_version(pickle_module)\n\u001B[1;32m    421\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _use_new_zipfile_serialization:\n\u001B[0;32m--> 422\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_zipfile_writer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_zipfile:\n\u001B[1;32m    423\u001B[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001B[1;32m    424\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[0;32m~/Coeuraj/v_env/lib/python3.9/site-packages/torch/serialization.py:309\u001B[0m, in \u001B[0;36m_open_zipfile_writer\u001B[0;34m(name_or_buffer)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    308\u001B[0m     container \u001B[38;5;241m=\u001B[39m _open_zipfile_writer_buffer\n\u001B[0;32m--> 309\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcontainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/Coeuraj/v_env/lib/python3.9/site-packages/torch/serialization.py:287\u001B[0m, in \u001B[0;36m_open_zipfile_writer_file.__init__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    286\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, name) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 287\u001B[0m     \u001B[38;5;28msuper\u001B[39m(_open_zipfile_writer_file, \u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPyTorchFileWriter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Parent directory model_output does not exist."
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "trainer.save_history_('model_output')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "history = load_history('model_output')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plot_history(history)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = MLModel()\n",
    "model = load_model(model, 'model_output/model.pth')\n",
    "test_loss, test_accuracy = trainer.test(model, trainer.val_loader)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(f'Model accuracy on test: {test_accuracy}')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
